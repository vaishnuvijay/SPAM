# -*- coding: utf-8 -*-
"""spam filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1chgoKaBerFYMxvCG67vzRo6Ut4dRdvhR

<div style = "color:PINK;background-color:black;font-size:4em;text-align:center;padding:3%;font-weight:bold">SPAM DETECTION</div>

![](https://i.gifer.com/Ou1t.gif)
"""

import pandas as pd
from sklearn import preprocessing
from sklearn.feature_extraction.text import CountVectorizer
import seaborn as sns
import matplotlib.pyplot as plt
df=pd.read_csv("C:/Users/user2/Desktop/spam1.csv",encoding="ISO-8859-1")
df

df.info()

df.shape

df.describe()

df.isnull().sum()

label=preprocessing.LabelEncoder()
label1=label.fit_transform(df["v1"])
label1

cvt=CountVectorizer()
x=cvt.fit_transform(df["v2"])
arry=x.toarray()
arry

df["spam"]=label1
df

"""<span class="label label-default" style="color:cyan;background-color:pink;font-size:4em">HEATMAPðŸ’¥</span>"""

z=df.corr()
sns.heatmap(z)

la1=df.v1.unique()
la1

"""<span class="label label-default" style="color:cyan;background-color:pink;font-size:4em">countplot and pie diagram</span>"""

plt.figure(figsize=(18,6),facecolor="pink")
plt.subplot(1,2,1)
sns.countplot(x=df["spam"],color="green")
plt.title("countplot of spam and ham",fontsize=20)
plt.subplot(1,2,2)
plt.pie(x=df["spam"].value_counts(),labels=la1,autopct="%1.2f%%",colors=["red","yellow","green"])
plt.title("pie diagram",fontsize=20)

"""<span class="label label-default" style="color:cyan;background-color:pink;font-size:4em">logistic regression</span>"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
x_train,x_test,y_train,y_test=train_test_split(x,label1)
reg=LogisticRegression()
reg.fit(x_train,y_train)
rs=reg.predict(x_test)
rs

from collections import Counter
Counter(rs)

Counter(y_test)

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,plot_confusion_matrix
#training score
y1=reg.score(x_train,y_train)
print("training accuracy of logistic regression is ",y1)

#model accuracy
x=accuracy_score(rs,y_test)
print("model accuracy of logistic regression is ",x)

print(classification_report(y_test,rs))

confusion_matrix(y_test,rs)

plot_confusion_matrix(reg,x_test,y_test)

"""<span class="label label-default" style="color:cyan;background-color:pink;font-size:4em">random forest classifier</span>

"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier()
rf.fit(x_train,y_train)
pre=rf.predict(x_test)
pre

y2=rf.score(x_train,y_train)
print("training accuracy of rfc is ",y2)

x3=accuracy_score(pre,y_test)
print("model accuracy of rfc is ",x3)

print(classification_report(y_test,pre))

confusion_matrix(y_test,pre)
plot_confusion_matrix(rf,x_test,y_test)

"""<span class="label label-default" style="color:cyan;background-color:pink;font-size:4em">SVM</span>"""

from sklearn.svm import SVC
svm=SVC()
svm.fit(x_train,y_train)
pr1=svm.predict(x_test)
pr1

y3=svm.score(x_train,y_train)
print("training accuracy of svm is ",y3)

x1=accuracy_score(pr1,y_test)
print("model accuracy of svm is ",x1)

confusion_matrix(y_test,pr1)

plot_confusion_matrix(svm,x_test,y_test)

"""<span class="label label-default" style="color:cyan;background-color:pink;font-size:4em">KNN</span>"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)
predict3=knn.predict(x_test)
predict3

y5=knn.score(x_train,y_train)
print("training accuracy of KNN is ",y5)

x5=accuracy_score(predict3,y_test)
print("model accuracy of knn is ",x5)

print(classification_report(y_test,pr1))

confusion_matrix(y_test,pr1)

plot_confusion_matrix(svm,x_test,y_test)

import pandas as pd
o={"model":["logistic regrssion","random forest","svm","knn"],"accuracy score":[y1,y2,y3,y5],"model accuracy":[x,x3,x1,x5]}
v=pd.DataFrame(o)
v.sort_values(by="accuracy score",ascending =False).style.background_gradient(cmap="cubehelix")

""" <div style = "color:PINK;background-color:black;font-size:2em;text-align:center;padding:3%;font-weight:bold">RANDOM FOREST IS MORE ACCURATE FOR PREDICTION</div>"""

